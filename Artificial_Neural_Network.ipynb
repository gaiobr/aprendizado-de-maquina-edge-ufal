{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial_Neural_Network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcA9arJTX2+3OgfJxksHT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaiobr/aprendizado-de-maquina-edge-ufal/blob/master/Artificial_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyouyuG591bx",
        "colab_type": "text"
      },
      "source": [
        "# **Dados de Qualidade de Vinho Tinto**\n",
        "\n",
        "Dataset com dados fisíco-químicos e sensorial sobre vinhos tintos da denominação de origem controlada \"Vinho Verde\".\n",
        "\n",
        "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88-KDzJvTG7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8d81421b-eeba-4ad7-a117-e4309b651ef6"
      },
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgjwmKMr978v",
        "colab_type": "text"
      },
      "source": [
        "## **1. Importar bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrI3y9pC955A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importar bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cQ-Nhun-E2w",
        "colab_type": "text"
      },
      "source": [
        "## **2. Carregar conjunto de dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbjKZxRh-IT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregar dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/datasets/winequality-red.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSNkqWPk-KQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "11a36fa2-af58-4173-93c8-4fe53bdb6377"
      },
      "source": [
        "# Verificar dataframe\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phMMs9Cr-lp2",
        "colab_type": "text"
      },
      "source": [
        "## **3. Limpar e organizar os dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1YN88dY-oVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificar e excluir valores NaN, ? ou dados faltantes\n",
        "df = df.dropna()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDFF6qIL-ts9",
        "colab_type": "text"
      },
      "source": [
        "## **4. Re-escalar os dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4omRGN--7hV",
        "colab_type": "text"
      },
      "source": [
        "### **Re-escalar usando máximo e mínimo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDID4esrATy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.iloc[:,:-1] = (df.iloc[:,:-1] - df.iloc[:,:-1].min())/(df.iloc[:,:-1].max()-df.iloc[:,:-1].min())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG7cLPuY_ESs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "9be45421-d5d0-4133-85b7-fa9d46d03caf"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.247788</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.106845</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.098940</td>\n",
              "      <td>0.567548</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.283186</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.116438</td>\n",
              "      <td>0.143573</td>\n",
              "      <td>0.338028</td>\n",
              "      <td>0.215548</td>\n",
              "      <td>0.494126</td>\n",
              "      <td>0.362205</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.215385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.283186</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>0.133556</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.169611</td>\n",
              "      <td>0.508811</td>\n",
              "      <td>0.409449</td>\n",
              "      <td>0.191617</td>\n",
              "      <td>0.215385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.584071</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.105175</td>\n",
              "      <td>0.225352</td>\n",
              "      <td>0.190813</td>\n",
              "      <td>0.582232</td>\n",
              "      <td>0.330709</td>\n",
              "      <td>0.149701</td>\n",
              "      <td>0.215385</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.247788</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.106845</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.098940</td>\n",
              "      <td>0.567548</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates   alcohol  quality\n",
              "0       0.247788          0.397260         0.00  ...   0.137725  0.153846        5\n",
              "1       0.283186          0.520548         0.00  ...   0.209581  0.215385        5\n",
              "2       0.283186          0.438356         0.04  ...   0.191617  0.215385        5\n",
              "3       0.584071          0.109589         0.56  ...   0.149701  0.215385        6\n",
              "4       0.247788          0.397260         0.00  ...   0.137725  0.153846        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uafwz3gPM0OG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "aae4ccf1-0595-488b-9c42-1877e987e2d4"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.329171</td>\n",
              "      <td>0.279329</td>\n",
              "      <td>0.270976</td>\n",
              "      <td>0.112247</td>\n",
              "      <td>0.125988</td>\n",
              "      <td>0.209506</td>\n",
              "      <td>0.142996</td>\n",
              "      <td>0.490211</td>\n",
              "      <td>0.449695</td>\n",
              "      <td>0.196496</td>\n",
              "      <td>0.311228</td>\n",
              "      <td>5.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.154079</td>\n",
              "      <td>0.122644</td>\n",
              "      <td>0.194801</td>\n",
              "      <td>0.096570</td>\n",
              "      <td>0.078573</td>\n",
              "      <td>0.147326</td>\n",
              "      <td>0.116238</td>\n",
              "      <td>0.138571</td>\n",
              "      <td>0.121564</td>\n",
              "      <td>0.101501</td>\n",
              "      <td>0.163949</td>\n",
              "      <td>0.807569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.221239</td>\n",
              "      <td>0.184932</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.096828</td>\n",
              "      <td>0.084507</td>\n",
              "      <td>0.056537</td>\n",
              "      <td>0.406021</td>\n",
              "      <td>0.370079</td>\n",
              "      <td>0.131737</td>\n",
              "      <td>0.169231</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.292035</td>\n",
              "      <td>0.273973</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.089041</td>\n",
              "      <td>0.111853</td>\n",
              "      <td>0.183099</td>\n",
              "      <td>0.113074</td>\n",
              "      <td>0.490455</td>\n",
              "      <td>0.448819</td>\n",
              "      <td>0.173653</td>\n",
              "      <td>0.276923</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.407080</td>\n",
              "      <td>0.356164</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.116438</td>\n",
              "      <td>0.130217</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>0.197880</td>\n",
              "      <td>0.570117</td>\n",
              "      <td>0.519685</td>\n",
              "      <td>0.239521</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed acidity  volatile acidity  ...      alcohol      quality\n",
              "count    1599.000000       1599.000000  ...  1599.000000  1599.000000\n",
              "mean        0.329171          0.279329  ...     0.311228     5.636023\n",
              "std         0.154079          0.122644  ...     0.163949     0.807569\n",
              "min         0.000000          0.000000  ...     0.000000     3.000000\n",
              "25%         0.221239          0.184932  ...     0.169231     5.000000\n",
              "50%         0.292035          0.273973  ...     0.276923     6.000000\n",
              "75%         0.407080          0.356164  ...     0.415385     6.000000\n",
              "max         1.000000          1.000000  ...     1.000000     8.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9yh8M0PAsU2",
        "colab_type": "text"
      },
      "source": [
        "## **5. Organizar os dados para modelagem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beaPrqxoAzU5",
        "colab_type": "text"
      },
      "source": [
        "### **Dividir os dados entre atributos descritores e atributos de classe (target)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2__DaBLAwVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "f5654657-093c-4a14-b749-997e93afe318"
      },
      "source": [
        "# Dividir dados em atributos descritores e atributo de classe\n",
        "df_x = df.iloc[:,:-1]\n",
        "df_x.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.247788</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.106845</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.098940</td>\n",
              "      <td>0.567548</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.283186</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.116438</td>\n",
              "      <td>0.143573</td>\n",
              "      <td>0.338028</td>\n",
              "      <td>0.215548</td>\n",
              "      <td>0.494126</td>\n",
              "      <td>0.362205</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.215385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.283186</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>0.133556</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.169611</td>\n",
              "      <td>0.508811</td>\n",
              "      <td>0.409449</td>\n",
              "      <td>0.191617</td>\n",
              "      <td>0.215385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.584071</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.105175</td>\n",
              "      <td>0.225352</td>\n",
              "      <td>0.190813</td>\n",
              "      <td>0.582232</td>\n",
              "      <td>0.330709</td>\n",
              "      <td>0.149701</td>\n",
              "      <td>0.215385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.247788</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>0.106845</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>0.098940</td>\n",
              "      <td>0.567548</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...        pH  sulphates   alcohol\n",
              "0       0.247788          0.397260         0.00  ...  0.606299   0.137725  0.153846\n",
              "1       0.283186          0.520548         0.00  ...  0.362205   0.209581  0.215385\n",
              "2       0.283186          0.438356         0.04  ...  0.409449   0.191617  0.215385\n",
              "3       0.584071          0.109589         0.56  ...  0.330709   0.149701  0.215385\n",
              "4       0.247788          0.397260         0.00  ...  0.606299   0.137725  0.153846\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnUYaqgmBFNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "d664f9c9-79f0-4896-a66a-520565c7e1d3"
      },
      "source": [
        "df_y = df.quality\n",
        "df_y.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5\n",
              "1    5\n",
              "2    5\n",
              "3    6\n",
              "4    5\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJDACg1dBKf9",
        "colab_type": "text"
      },
      "source": [
        "### **Dividir os dados entre treino e teste**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUfj5dt4BNNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregar biblioteca necessária\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWeu2AEYBUem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLPG-vFZBrkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "e6e3b729-446f-4020-a7e0-397f5ba9be18"
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>0.504425</td>\n",
              "      <td>0.102740</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.100167</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.095406</td>\n",
              "      <td>0.406021</td>\n",
              "      <td>0.377953</td>\n",
              "      <td>0.197605</td>\n",
              "      <td>0.676923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049</th>\n",
              "      <td>0.415929</td>\n",
              "      <td>0.260274</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.061644</td>\n",
              "      <td>0.120200</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>0.038869</td>\n",
              "      <td>0.511747</td>\n",
              "      <td>0.417323</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.369231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0.203540</td>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.143836</td>\n",
              "      <td>0.108514</td>\n",
              "      <td>0.084507</td>\n",
              "      <td>0.074205</td>\n",
              "      <td>0.633627</td>\n",
              "      <td>0.748031</td>\n",
              "      <td>0.347305</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>0.681416</td>\n",
              "      <td>0.260274</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.089041</td>\n",
              "      <td>0.128548</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.028269</td>\n",
              "      <td>0.743759</td>\n",
              "      <td>0.354331</td>\n",
              "      <td>0.065868</td>\n",
              "      <td>0.184615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0.690265</td>\n",
              "      <td>0.191781</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.075342</td>\n",
              "      <td>0.078464</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>0.063604</td>\n",
              "      <td>0.685022</td>\n",
              "      <td>0.236220</td>\n",
              "      <td>0.161677</td>\n",
              "      <td>0.138462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  ...  sulphates   alcohol\n",
              "533        0.504425          0.102740  ...   0.197605  0.676923\n",
              "1049       0.415929          0.260274  ...   0.263473  0.369231\n",
              "276        0.203540          0.287671  ...   0.347305  0.153846\n",
              "581        0.681416          0.260274  ...   0.065868  0.184615\n",
              "596        0.690265          0.191781  ...   0.161677  0.138462\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgQY4dlLBvHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "ffd4d15b-8440-41e4-df9c-6ba82ccadd10"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "533     6\n",
              "1049    6\n",
              "276     6\n",
              "581     5\n",
              "596     6\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ5aGJCgB0ia",
        "colab_type": "text"
      },
      "source": [
        "## **6. Definir algoritmo de aprendizado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jLEZiZ9RQWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eat_IytRYmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definir modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', max_iter=1000)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxWqciLARh0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "29373c7d-c89c-4336-99a7-8a29f5225f7a"
      },
      "source": [
        "# Treinar modelo\n",
        "classificador.fit(x_train, y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r94OXRpiRlap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "4f9ea93d-448e-4898-d328-0393fdf6d48f"
      },
      "source": [
        "# Realizar classificação\n",
        "classificacao = classificador.predict(x_test)\n",
        "classificacao"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 7, 5, 5, 6, 6, 6, 5, 6,\n",
              "       5, 5, 6, 5, 5, 6, 6, 6, 5, 5, 6, 6, 7, 5, 6, 6, 6, 6, 5, 5, 6, 5,\n",
              "       6, 6, 6, 6, 7, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6,\n",
              "       5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 6, 5, 5, 5, 5, 5,\n",
              "       6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 6, 5, 5, 7, 5, 5, 6, 5, 5, 6, 5, 5,\n",
              "       5, 6, 6, 6, 5, 6, 7, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6, 5, 5, 6, 5, 6,\n",
              "       6, 7, 6, 6, 5, 6, 6, 6, 5, 5, 7, 5, 6, 5, 5, 6, 6, 6, 5, 5, 6, 5,\n",
              "       5, 5, 5, 5, 6, 5, 5, 6, 5, 6, 5, 5, 7, 7, 6, 5, 6, 5, 5, 6, 5, 6,\n",
              "       6, 6, 6, 7, 5, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 7, 5, 5, 7, 5, 7,\n",
              "       5, 6, 6, 5, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6,\n",
              "       6, 7, 6, 5, 6, 6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 7,\n",
              "       6, 6, 5, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 5, 7, 6, 7, 7, 5, 5,\n",
              "       5, 5, 5, 5, 6, 5, 5, 6, 5, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5,\n",
              "       6, 5, 6, 5, 5, 6, 5, 6, 5, 5, 6, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_pcDyEYRtcR",
        "colab_type": "text"
      },
      "source": [
        "## **7. Avaliar classificador**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jI_R82KR1ZN",
        "colab_type": "text"
      },
      "source": [
        "**Acurácia**: taxa de acertos do classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUPM3s3wR55z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcular acurácia\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8D47I4dRwn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7aca896f-6b4f-41b5-8cce-c14953cb1dda"
      },
      "source": [
        "acuracia = accuracy_score(y_test, classificacao)\n",
        "round(acuracia, 3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdlqy3faTHsA",
        "colab_type": "text"
      },
      "source": [
        "**Precisão**: taxa de instâncias classificadas como positivas que são realmente positivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnl0HuulTMkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcular precisão\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcdKC-eoTQW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "080d17be-fffc-4178-d94e-2206ac9cab6a"
      },
      "source": [
        "precisao = precision_score(y_test, classificacao, average='micro')\n",
        "round(precisao, 3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SANOQIbTvrT",
        "colab_type": "text"
      },
      "source": [
        "**Recall**: taxa de instâncias positivas classificadas corretamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fysypLsJTzKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcular recall (revocação)\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tay03nIqT3EJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57ed638a-184e-44b2-f45b-9c86d8deb2d8"
      },
      "source": [
        "recall = recall_score(y_test, classificacao, average='micro')\n",
        "round(recall, 3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW8fvkTmT9Ft",
        "colab_type": "text"
      },
      "source": [
        "**F1-score**: balanço entre precisão e recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phbQQS_UB9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcular F1-score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT0ZZ5UdUGff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c99698db-2c94-46c4-d952-f90c1c018228"
      },
      "source": [
        "f1 = f1_score(y_test, classificacao, average='micro')\n",
        "round(f1, 3)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_eALnoiUXr-",
        "colab_type": "text"
      },
      "source": [
        "### **Curva ROC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXNsZ_gGUZZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotar curva roc\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZds9TmkUcxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, classificacao, pos_label=8)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcFJR_GWUib2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d5460225-b874-435e-f724-a3d62a2a42bc"
      },
      "source": [
        "plt.plot(fpr,tpr,marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiro Positivos')\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMACR9-zUp1T",
        "colab_type": "text"
      },
      "source": [
        "### **Área sob a curva**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAA2_yZ3Utl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEzGrQoZUw_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "dfe1f082-b2c2-464f-d197-ba0caaa385d8"
      },
      "source": [
        "auc = roc_auc_score(y_test, classificacao)\n",
        "round(auc, 3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-9189673f100f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassificacao\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    379\u001b[0m                              \"instead\".format(max_fpr))\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m    383\u001b[0m                                          multi_class, average, sample_weight)\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAFhpSC5VD7N",
        "colab_type": "text"
      },
      "source": [
        "### **Validação cruzada***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikHweUEOVG5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avaliar modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyWlXGhVLGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definir modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', max_iter=1000)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0klu9yNAVTON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4f79e0e8-3d27-4fa4-80df-d6db67ec79dc"
      },
      "source": [
        "# Calcular os scores\n",
        "scores = cross_val_score(classificador, df_x, df_y, cv=10)\n",
        "scores"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.475     , 0.6375    , 0.6       , 0.50625   , 0.55      ,\n",
              "       0.725     , 0.6375    , 0.5625    , 0.65625   , 0.58490566])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh9yQDhEWNci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4979f22-41ab-43cd-f559-894eacc840f2"
      },
      "source": [
        "round(scores.mean(), 3), round(scores.std(), 3)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.593, 0.071)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF1qWzWRWVyv",
        "colab_type": "text"
      },
      "source": [
        "### **Comparar MLP com Árvore de Decisão e Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af_6bDuJWaXh",
        "colab_type": "text"
      },
      "source": [
        "**Validação Cruzada**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpnE59mUWZhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdtj-dP5Whp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criar árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "# Calcular os scores\n",
        "scores_arvore = cross_val_score(arvore, df_x, df_y, cv = 10)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSnIcGO4Wr2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criar random forest\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "# Calcular os scores\n",
        "scores_floresta = cross_val_score(floresta, df_x, df_y, cv = 10)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUvc-kGWzq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criar rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', max_iter=1000)\n",
        "\n",
        "# Calcular os scores\n",
        "scores_mlp = cross_val_score(mlp, df_x, df_y, cv = 10) "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2yUgHP_XLjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7964a1ee-ec8b-45e1-e82e-735660f5fa6d"
      },
      "source": [
        "print('Árvore de Decisão: ', round(scores_arvore.mean(), 3), round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(), 3), round(scores.std(), 3))\n",
        "print('MLP: ', round(scores_mlp.mean(), 3), round(scores_mlp.std(), 3))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.469 0.035\n",
            "Random Forest:  0.593 0.071\n",
            "MLP:  0.589 0.067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QBfH8emXgxP",
        "colab_type": "text"
      },
      "source": [
        "## **8. Otimização de Parâmetros**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3Vc3Du4-liq",
        "colab_type": "text"
      },
      "source": [
        "#### **Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-ZzH8NBXj2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uar_0t8YRuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes': [(10), (50), (100), (50,10), (100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [500, 1000, 2000]\n",
        "              }\n",
        "]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGV4A7egYoYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = RandomizedSearchCV(MLPClassifier(), param_grid, cv=5, scoring='accuracy')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaKH7Ze6YuxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b484c2a-c478-4173-eadd-eb68f1c120ae"
      },
      "source": [
        "mlp.fit(df_x, df_y)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 50, 100,\n",
              "                                                                (50, 10),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6d_fza5Zy0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "eed5b126-c57c-406c-807d-b8bf448bd590"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': 50, 'activation': 'logistic'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahAIUcJEZ3u8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71753bad-4e73-4ca8-9181-1cb8f7f9472d"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaN4-ksiZ7t_",
        "colab_type": "text"
      },
      "source": [
        "#### **Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgqKL1YEZ9BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VKI3kynaAyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = GridSearchCV(MLPClassifier(), param_grid, cv=5, scoring='accuracy')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg9lHPqTaGyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1677e1b9-2d2b-4a72-f0ad-34537ef82972"
      },
      "source": [
        "mlp.fit(df_x, df_y)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 50, 100, (50, 10),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [500, 1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2sRIsoPrBf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9df4e5a1-cb0d-4fc4-fd31-7c6cd4f4a851"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'logistic', 'hidden_layer_sizes': 10, 'max_iter': 2000, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy5rw5qlrHUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7add9b23-db70-450a-b3d1-ee659d3b7e37"
      },
      "source": [
        "print(round(mlp.best_score_, 3))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8DE_2Br7e-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc5d6782-4000-4f8c-de69-6a4b74a82c11"
      },
      "source": [
        "mlp.cv_results_"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 0.30237904,  1.06885638,  1.23476439,  0.31337109,  1.69522429,\n",
              "         1.39792738,  0.28579612,  1.68896685,  1.26060619,  0.58138895,\n",
              "         1.37301946,  1.17569261,  0.57665625,  1.86319327,  1.0851685 ,\n",
              "         0.59146156,  2.06482949,  1.09288735,  0.82374296,  1.75102997,\n",
              "         1.11914692,  0.86987143,  2.41945844,  1.02311659,  0.88306742,\n",
              "         2.29868779,  1.02934184,  0.80534978,  1.6892374 ,  0.96113634,\n",
              "         0.86236424,  2.28077741,  0.8486043 ,  0.84553919,  2.32996483,\n",
              "         0.91975522,  1.72697206,  4.20297494,  1.44502511,  1.7081862 ,\n",
              "         5.99131498,  1.29999933,  1.73919868,  5.85500956,  1.16332078,\n",
              "         0.68717456,  0.46809053,  1.41530352,  1.36266832,  0.45688972,\n",
              "         2.16917434,  2.67209516,  0.47340984,  2.13404484,  2.55986543,\n",
              "         0.45298357,  2.3379817 ,  5.11412625,  0.44479427,  3.03877792,\n",
              "        10.10227036,  0.44943681,  2.93031139,  4.48395038,  0.59095192,\n",
              "         3.15586405,  8.85387902,  0.61420765,  3.38998828, 17.61485243,\n",
              "         0.55264997,  3.15379829,  3.07091804,  0.79124074,  2.88752303,\n",
              "         6.05138083,  0.82004242,  4.10602188, 12.10312915,  0.817946  ,\n",
              "         3.9648356 ,  8.17772613,  1.40945067,  6.06456175, 14.32619305,\n",
              "         1.41672349,  6.07146559, 26.98209214,  1.342765  ,  6.02074699,\n",
              "         0.77597208,  1.31956658,  1.50624609,  1.53891373,  2.23654323,\n",
              "         1.98522878,  3.12224088,  2.04702687,  1.9819263 ,  3.10018229,\n",
              "         2.3274179 ,  2.1700841 ,  6.30640664,  3.42593699,  1.95609121,\n",
              "        12.59051323,  3.29670401,  1.94203696,  6.25193024,  3.46160703,\n",
              "         2.04698424, 10.70869889,  4.84444885,  2.21594925, 19.23372021,\n",
              "         5.15514479,  2.2529355 ,  3.50278783,  2.8270834 ,  3.14391398,\n",
              "         7.10370951,  3.89153619,  4.48672681, 14.21482892,  3.90676947,\n",
              "         7.44333463,  8.13014197,  8.37649159,  7.4326364 , 12.25804224,\n",
              "        11.28024783, 18.70470223, 11.5635366 , 10.63678427, 17.08717375,\n",
              "         0.61841793,  1.3540494 ,  1.49772844,  1.21327448,  2.19495587,\n",
              "         2.4035109 ,  1.66158037,  2.37642407,  1.86130505,  1.67716532,\n",
              "         1.89634995,  2.04247661,  3.31742954,  2.91225486,  3.8853404 ,\n",
              "         7.7089467 ,  3.06226277,  4.03849244,  2.56789923,  2.58305507,\n",
              "         2.76496096,  5.15250611,  4.19710011,  5.51765108, 10.23429694,\n",
              "         4.17875233,  5.81485591,  1.93218088,  2.3938849 ,  2.50509205,\n",
              "         3.85734181,  3.98095536,  3.40569997,  7.84659433,  5.08184452,\n",
              "         3.6415926 ,  4.35655437,  5.93165507,  6.50626035,  8.83390522,\n",
              "        10.98172855,  5.83751655, 17.95497856, 10.58112874,  7.49682522]),\n",
              " 'mean_score_time': array([0.00145984, 0.00190701, 0.00186496, 0.00140066, 0.00138874,\n",
              "        0.00140452, 0.00137687, 0.00144072, 0.00138683, 0.00200038,\n",
              "        0.0019484 , 0.00149369, 0.00199585, 0.00148358, 0.00145373,\n",
              "        0.00198069, 0.0014864 , 0.00150704, 0.00213737, 0.00254116,\n",
              "        0.00186892, 0.00204091, 0.00183425, 0.00183325, 0.00211859,\n",
              "        0.00185652, 0.00184226, 0.00202565, 0.00199943, 0.00152054,\n",
              "        0.0019927 , 0.00150065, 0.00150208, 0.00199833, 0.00149317,\n",
              "        0.00150399, 0.00222797, 0.0022398 , 0.00225229, 0.00221605,\n",
              "        0.00227361, 0.00227022, 0.00229325, 0.00247269, 0.0022665 ,\n",
              "        0.00193362, 0.00146337, 0.00196123, 0.00194621, 0.00144391,\n",
              "        0.00148082, 0.00202231, 0.00145721, 0.00146179, 0.00253649,\n",
              "        0.0018158 , 0.00226955, 0.00249801, 0.0018291 , 0.00182676,\n",
              "        0.00274186, 0.00182662, 0.00182066, 0.00319924, 0.0030508 ,\n",
              "        0.00303411, 0.00327988, 0.00296755, 0.00303202, 0.00318384,\n",
              "        0.00301323, 0.00299325, 0.00270681, 0.00190063, 0.00240846,\n",
              "        0.0027297 , 0.00190763, 0.00195665, 0.00283704, 0.00188127,\n",
              "        0.0019496 , 0.00483394, 0.00392776, 0.00401845, 0.00389199,\n",
              "        0.005302  , 0.00390863, 0.00395002, 0.00385842, 0.00389237,\n",
              "        0.00205402, 0.0019825 , 0.00195413, 0.0019845 , 0.00150805,\n",
              "        0.00148458, 0.00235047, 0.00149918, 0.00154729, 0.00284362,\n",
              "        0.00232787, 0.00203309, 0.00293469, 0.00208507, 0.00192399,\n",
              "        0.00303469, 0.00183921, 0.00187268, 0.00389619, 0.00395484,\n",
              "        0.00303655, 0.00386062, 0.00298872, 0.00308237, 0.00389328,\n",
              "        0.00305624, 0.00300589, 0.00300379, 0.00242524, 0.00255561,\n",
              "        0.00358844, 0.00198269, 0.00201621, 0.00306292, 0.00198617,\n",
              "        0.00201073, 0.0046226 , 0.00400252, 0.00425558, 0.00460482,\n",
              "        0.00411363, 0.00439377, 0.00463991, 0.00412664, 0.00437913,\n",
              "        0.00196013, 0.00199289, 0.00197592, 0.00173502, 0.001614  ,\n",
              "        0.00140524, 0.0015358 , 0.00141664, 0.00141206, 0.00224247,\n",
              "        0.00201726, 0.00200453, 0.00223093, 0.00154939, 0.00193033,\n",
              "        0.00235291, 0.00153275, 0.00155516, 0.00238948, 0.00247049,\n",
              "        0.00244775, 0.00259423, 0.00205693, 0.00276213, 0.00227141,\n",
              "        0.00204992, 0.00203953, 0.00221539, 0.00200868, 0.00196538,\n",
              "        0.00259714, 0.0016953 , 0.00161405, 0.00227189, 0.00163274,\n",
              "        0.00161681, 0.00258522, 0.00251446, 0.00254259, 0.00265021,\n",
              "        0.00301003, 0.00257363, 0.00265851, 0.00257568, 0.00257511]),\n",
              " 'mean_test_score': array([0.57726685, 0.55724726, 0.58726097, 0.57789185, 0.58350705,\n",
              "        0.58851293, 0.57788989, 0.56599334, 0.59038793, 0.57789185,\n",
              "        0.5672453 , 0.58726097, 0.57851489, 0.57849922, 0.58476685,\n",
              "        0.57976881, 0.57662618, 0.58851489, 0.57851293, 0.5591203 ,\n",
              "        0.58538989, 0.57851489, 0.57662813, 0.58413401, 0.57726489,\n",
              "        0.57350118, 0.58226097, 0.57726685, 0.58288597, 0.58351293,\n",
              "        0.57726685, 0.58788009, 0.58476489, 0.57664185, 0.58850705,\n",
              "        0.58288793, 0.57726685, 0.58224922, 0.58350705, 0.57726685,\n",
              "        0.59351097, 0.57976097, 0.57601293, 0.58788793, 0.58288401,\n",
              "        0.55846395, 0.42589342, 0.58663597, 0.54784679, 0.42589146,\n",
              "        0.59539381, 0.53847179, 0.42714146, 0.59726097, 0.52470611,\n",
              "        0.42401646, 0.58663989, 0.49285071, 0.42714146, 0.59226685,\n",
              "        0.46214146, 0.42589146, 0.58914381, 0.54909483, 0.42589146,\n",
              "        0.58851489, 0.48659875, 0.42589146, 0.58914185, 0.46655368,\n",
              "        0.42589146, 0.59352273, 0.53908111, 0.42589146, 0.59789969,\n",
              "        0.50844632, 0.42589146, 0.59039773, 0.47091889, 0.42589146,\n",
              "        0.58788597, 0.52972571, 0.42589146, 0.59101489, 0.48781544,\n",
              "        0.42589146, 0.58789381, 0.46906348, 0.42589146, 0.59164577,\n",
              "        0.53910071, 0.56410658, 0.59101489, 0.54783699, 0.58099922,\n",
              "        0.58099922, 0.53471787, 0.57600118, 0.58538009, 0.49717672,\n",
              "        0.56286246, 0.58726097, 0.49093456, 0.57663205, 0.58788793,\n",
              "        0.47096983, 0.57537618, 0.58538205, 0.51721395, 0.55724138,\n",
              "        0.59351489, 0.47157132, 0.58225313, 0.58976097, 0.48718652,\n",
              "        0.56975118, 0.58788401, 0.49530956, 0.57412618, 0.57161834,\n",
              "        0.46716497, 0.57788401, 0.57224138, 0.46904781, 0.58288205,\n",
              "        0.55849138, 0.46906348, 0.58475705, 0.56224138, 0.48596199,\n",
              "        0.58975705, 0.5422355 , 0.48221003, 0.58851489, 0.55036834,\n",
              "        0.56850118, 0.54721003, 0.58913009, 0.58100705, 0.54156348,\n",
              "        0.59100901, 0.5678703 , 0.56661638, 0.59351685, 0.51092281,\n",
              "        0.55784483, 0.59538597, 0.51594044, 0.57599922, 0.57911442,\n",
              "        0.50281348, 0.57974334, 0.57224726, 0.50283111, 0.56286442,\n",
              "        0.5809953 , 0.48846395, 0.5784953 , 0.58038793, 0.4915674 ,\n",
              "        0.58099726, 0.58475118, 0.51596199, 0.55973942, 0.58600313,\n",
              "        0.51405564, 0.59101685, 0.59225705, 0.51219632, 0.59038401,\n",
              "        0.58600313, 0.48529976, 0.56849334, 0.56910266, 0.46652429,\n",
              "        0.59476881, 0.55535266, 0.4715674 , 0.59289381, 0.56161442]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[500, 500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500,\n",
              "                    500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500,\n",
              "                    500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([ 81, 118,  37,  77,  53,  29,  79, 107,  19,  77, 105,  39,  72,\n",
              "         75,  47,  68,  90,  26,  74, 114,  44,  72,  89,  51,  86,  96,\n",
              "         59,  81,  56,  52,  81,  36,  48,  87,  30,  55,  81,  61,  53,\n",
              "         81,   9,  69,  91,  33,  57, 116, 168,  41, 123, 169,   3, 130,\n",
              "        166,   2, 133, 180,  40, 145, 166,  11, 165, 169,  23, 122, 169,\n",
              "         27, 151, 169,  24, 163, 169,   6, 129, 169,   1, 140, 169,  18,\n",
              "        158, 169,  34, 132, 169,  15, 149, 169,  31, 159, 169,  13, 128,\n",
              "        108,  15, 124,  63,  63, 131,  92,  46, 143, 110,  37, 147,  88,\n",
              "         32, 157,  94,  45, 134, 119,   8, 155,  60,  21, 150, 100,  35,\n",
              "        144,  95,  99, 162,  80,  98, 161,  58, 115, 159,  49, 111, 152,\n",
              "         22, 126, 154,  27, 121, 102, 125,  25,  62, 127,  17, 104, 106,\n",
              "          7, 139, 117,   4, 136,  93,  71, 142,  70,  97, 141, 109,  66,\n",
              "        148,  76,  67, 146,  65,  50, 135, 113,  42, 137,  14,  12, 138,\n",
              "         20,  42, 153, 103, 101, 164,   5, 120, 156,  10, 112], dtype=int32),\n",
              " 'split0_test_score': array([0.509375, 0.515625, 0.534375, 0.509375, 0.55    , 0.534375,\n",
              "        0.509375, 0.53125 , 0.5375  , 0.509375, 0.54375 , 0.540625,\n",
              "        0.509375, 0.55625 , 0.53125 , 0.509375, 0.55    , 0.534375,\n",
              "        0.509375, 0.528125, 0.534375, 0.509375, 0.540625, 0.540625,\n",
              "        0.509375, 0.540625, 0.525   , 0.509375, 0.5625  , 0.534375,\n",
              "        0.509375, 0.540625, 0.540625, 0.509375, 0.55    , 0.534375,\n",
              "        0.509375, 0.54375 , 0.525   , 0.509375, 0.55625 , 0.53125 ,\n",
              "        0.509375, 0.55    , 0.53125 , 0.578125, 0.428125, 0.534375,\n",
              "        0.540625, 0.43125 , 0.55    , 0.53125 , 0.428125, 0.55    ,\n",
              "        0.521875, 0.428125, 0.53125 , 0.421875, 0.4375  , 0.546875,\n",
              "        0.440625, 0.428125, 0.5375  , 0.515625, 0.428125, 0.54375 ,\n",
              "        0.475   , 0.428125, 0.546875, 0.49375 , 0.428125, 0.54375 ,\n",
              "        0.534375, 0.428125, 0.5375  , 0.528125, 0.428125, 0.54375 ,\n",
              "        0.434375, 0.428125, 0.55    , 0.509375, 0.428125, 0.5375  ,\n",
              "        0.45625 , 0.428125, 0.534375, 0.45625 , 0.428125, 0.546875,\n",
              "        0.48125 , 0.528125, 0.534375, 0.528125, 0.55    , 0.54375 ,\n",
              "        0.528125, 0.54375 , 0.528125, 0.53125 , 0.53125 , 0.534375,\n",
              "        0.5     , 0.546875, 0.540625, 0.428125, 0.546875, 0.5375  ,\n",
              "        0.4875  , 0.515625, 0.5375  , 0.459375, 0.55    , 0.528125,\n",
              "        0.43125 , 0.5375  , 0.534375, 0.4625  , 0.5375  , 0.5     ,\n",
              "        0.465625, 0.5375  , 0.528125, 0.45625 , 0.55    , 0.521875,\n",
              "        0.465625, 0.546875, 0.521875, 0.5     , 0.54375 , 0.525   ,\n",
              "        0.45625 , 0.55625 , 0.53125 , 0.515625, 0.484375, 0.55    ,\n",
              "        0.546875, 0.49375 , 0.5625  , 0.528125, 0.525   , 0.5375  ,\n",
              "        0.546875, 0.540625, 0.54375 , 0.553125, 0.55625 , 0.540625,\n",
              "        0.484375, 0.553125, 0.54375 , 0.521875, 0.521875, 0.540625,\n",
              "        0.50625 , 0.55625 , 0.584375, 0.453125, 0.559375, 0.5375  ,\n",
              "        0.5     , 0.51875 , 0.55    , 0.509375, 0.528125, 0.546875,\n",
              "        0.509375, 0.53125 , 0.553125, 0.49375 , 0.534375, 0.55    ,\n",
              "        0.49375 , 0.546875, 0.546875, 0.4375  , 0.553125, 0.525   ]),\n",
              " 'split1_test_score': array([0.53125 , 0.525   , 0.546875, 0.53125 , 0.55625 , 0.54375 ,\n",
              "        0.53125 , 0.51875 , 0.565625, 0.53125 , 0.528125, 0.53125 ,\n",
              "        0.528125, 0.54375 , 0.528125, 0.53125 , 0.540625, 0.55    ,\n",
              "        0.53125 , 0.50625 , 0.53125 , 0.53125 , 0.55    , 0.53125 ,\n",
              "        0.53125 , 0.553125, 0.534375, 0.53125 , 0.525   , 0.528125,\n",
              "        0.53125 , 0.55    , 0.525   , 0.53125 , 0.54375 , 0.521875,\n",
              "        0.53125 , 0.55    , 0.534375, 0.53125 , 0.559375, 0.540625,\n",
              "        0.53125 , 0.54375 , 0.53125 , 0.55    , 0.425   , 0.559375,\n",
              "        0.528125, 0.425   , 0.553125, 0.44375 , 0.43125 , 0.565625,\n",
              "        0.478125, 0.415625, 0.54375 , 0.534375, 0.425   , 0.546875,\n",
              "        0.44375 , 0.425   , 0.54375 , 0.4875  , 0.425   , 0.5375  ,\n",
              "        0.4125  , 0.425   , 0.534375, 0.459375, 0.425   , 0.55    ,\n",
              "        0.5375  , 0.425   , 0.578125, 0.525   , 0.425   , 0.56875 ,\n",
              "        0.484375, 0.425   , 0.546875, 0.496875, 0.425   , 0.55625 ,\n",
              "        0.484375, 0.425   , 0.546875, 0.48125 , 0.425   , 0.540625,\n",
              "        0.528125, 0.5375  , 0.565625, 0.503125, 0.55    , 0.528125,\n",
              "        0.509375, 0.54375 , 0.5375  , 0.490625, 0.515625, 0.53125 ,\n",
              "        0.45    , 0.540625, 0.5375  , 0.403125, 0.546875, 0.54375 ,\n",
              "        0.459375, 0.5125  , 0.575   , 0.41875 , 0.55625 , 0.559375,\n",
              "        0.45    , 0.540625, 0.55625 , 0.45    , 0.534375, 0.54375 ,\n",
              "        0.490625, 0.534375, 0.540625, 0.459375, 0.534375, 0.503125,\n",
              "        0.446875, 0.546875, 0.528125, 0.43125 , 0.559375, 0.51875 ,\n",
              "        0.425   , 0.546875, 0.478125, 0.540625, 0.546875, 0.5375  ,\n",
              "        0.553125, 0.534375, 0.525   , 0.53125 , 0.525   , 0.534375,\n",
              "        0.4875  , 0.51875 , 0.55625 , 0.46875 , 0.54375 , 0.540625,\n",
              "        0.475   , 0.553125, 0.525   , 0.475   , 0.53125 , 0.5375  ,\n",
              "        0.45625 , 0.54375 , 0.534375, 0.4875  , 0.540625, 0.540625,\n",
              "        0.45625 , 0.55    , 0.559375, 0.496875, 0.571875, 0.540625,\n",
              "        0.49375 , 0.55625 , 0.5625  , 0.4875  , 0.540625, 0.56875 ,\n",
              "        0.45625 , 0.565625, 0.51875 , 0.459375, 0.553125, 0.54375 ]),\n",
              " 'split2_test_score': array([0.63125 , 0.575   , 0.634375, 0.63125 , 0.60625 , 0.63125 ,\n",
              "        0.63125 , 0.60625 , 0.628125, 0.63125 , 0.58125 , 0.6375  ,\n",
              "        0.634375, 0.60625 , 0.63125 , 0.634375, 0.60625 , 0.63125 ,\n",
              "        0.63125 , 0.58125 , 0.6375  , 0.63125 , 0.609375, 0.63125 ,\n",
              "        0.63125 , 0.5875  , 0.640625, 0.63125 , 0.609375, 0.640625,\n",
              "        0.63125 , 0.6375  , 0.63125 , 0.63125 , 0.646875, 0.63125 ,\n",
              "        0.63125 , 0.621875, 0.6375  , 0.63125 , 0.63125 , 0.628125,\n",
              "        0.63125 , 0.61875 , 0.6375  , 0.584375, 0.421875, 0.634375,\n",
              "        0.59375 , 0.425   , 0.63125 , 0.590625, 0.425   , 0.6375  ,\n",
              "        0.55625 , 0.425   , 0.634375, 0.46875 , 0.421875, 0.63125 ,\n",
              "        0.534375, 0.425   , 0.634375, 0.615625, 0.425   , 0.63125 ,\n",
              "        0.528125, 0.425   , 0.634375, 0.490625, 0.425   , 0.634375,\n",
              "        0.559375, 0.425   , 0.6375  , 0.525   , 0.425   , 0.621875,\n",
              "        0.46875 , 0.425   , 0.621875, 0.553125, 0.425   , 0.634375,\n",
              "        0.528125, 0.425   , 0.634375, 0.4875  , 0.425   , 0.646875,\n",
              "        0.596875, 0.590625, 0.634375, 0.621875, 0.60625 , 0.640625,\n",
              "        0.540625, 0.584375, 0.634375, 0.50625 , 0.590625, 0.640625,\n",
              "        0.471875, 0.60625 , 0.6375  , 0.471875, 0.59375 , 0.640625,\n",
              "        0.5375  , 0.58125 , 0.6375  , 0.5     , 0.609375, 0.6375  ,\n",
              "        0.553125, 0.603125, 0.6375  , 0.571875, 0.609375, 0.634375,\n",
              "        0.446875, 0.628125, 0.634375, 0.475   , 0.628125, 0.609375,\n",
              "        0.490625, 0.634375, 0.60625 , 0.521875, 0.634375, 0.5125  ,\n",
              "        0.496875, 0.61875 , 0.546875, 0.615625, 0.584375, 0.6625  ,\n",
              "        0.63125 , 0.5875  , 0.6375  , 0.634375, 0.609375, 0.66875 ,\n",
              "        0.528125, 0.58125 , 0.66875 , 0.540625, 0.596875, 0.65625 ,\n",
              "        0.53125 , 0.615625, 0.61875 , 0.48125 , 0.584375, 0.646875,\n",
              "        0.5     , 0.609375, 0.584375, 0.4875  , 0.615625, 0.6625  ,\n",
              "        0.571875, 0.584375, 0.646875, 0.534375, 0.6375  , 0.66875 ,\n",
              "        0.553125, 0.646875, 0.65    , 0.478125, 0.590625, 0.609375,\n",
              "        0.46875 , 0.6375  , 0.575   , 0.521875, 0.634375, 0.6125  ]),\n",
              " 'split3_test_score': array([0.5875  , 0.575   , 0.603125, 0.590625, 0.59375 , 0.6125  ,\n",
              "        0.59375 , 0.584375, 0.6     , 0.590625, 0.590625, 0.609375,\n",
              "        0.596875, 0.5875  , 0.60625 , 0.59375 , 0.584375, 0.603125,\n",
              "        0.6     , 0.5875  , 0.6     , 0.596875, 0.578125, 0.603125,\n",
              "        0.590625, 0.584375, 0.59375 , 0.5875  , 0.6     , 0.59375 ,\n",
              "        0.5875  , 0.603125, 0.603125, 0.584375, 0.590625, 0.60625 ,\n",
              "        0.5875  , 0.596875, 0.609375, 0.5875  , 0.603125, 0.58125 ,\n",
              "        0.5875  , 0.60625 , 0.6     , 0.5375  , 0.425   , 0.5875  ,\n",
              "        0.521875, 0.421875, 0.6125  , 0.571875, 0.425   , 0.615625,\n",
              "        0.5375  , 0.425   , 0.6     , 0.478125, 0.425   , 0.609375,\n",
              "        0.465625, 0.425   , 0.6     , 0.575   , 0.425   , 0.60625 ,\n",
              "        0.459375, 0.425   , 0.603125, 0.403125, 0.425   , 0.603125,\n",
              "        0.534375, 0.425   , 0.596875, 0.45    , 0.425   , 0.58125 ,\n",
              "        0.496875, 0.425   , 0.603125, 0.528125, 0.425   , 0.603125,\n",
              "        0.465625, 0.425   , 0.59375 , 0.41875 , 0.425   , 0.590625,\n",
              "        0.528125, 0.59375 , 0.596875, 0.546875, 0.6     , 0.59375 ,\n",
              "        0.546875, 0.60625 , 0.61875 , 0.475   , 0.596875, 0.6125  ,\n",
              "        0.5375  , 0.578125, 0.603125, 0.5     , 0.5875  , 0.59375 ,\n",
              "        0.559375, 0.590625, 0.59375 , 0.465625, 0.590625, 0.60625 ,\n",
              "        0.503125, 0.565625, 0.596875, 0.496875, 0.5875  , 0.590625,\n",
              "        0.46875 , 0.575   , 0.571875, 0.478125, 0.590625, 0.571875,\n",
              "        0.440625, 0.584375, 0.56875 , 0.4375  , 0.6     , 0.578125,\n",
              "        0.496875, 0.596875, 0.60625 , 0.56875 , 0.584375, 0.5875  ,\n",
              "        0.5625  , 0.590625, 0.615625, 0.553125, 0.5875  , 0.6     ,\n",
              "        0.515625, 0.596875, 0.590625, 0.5125  , 0.584375, 0.575   ,\n",
              "        0.521875, 0.5875  , 0.578125, 0.50625 , 0.59375 , 0.5875  ,\n",
              "        0.4375  , 0.590625, 0.578125, 0.521875, 0.59375 , 0.58125 ,\n",
              "        0.5125  , 0.5625  , 0.56875 , 0.540625, 0.590625, 0.59375 ,\n",
              "        0.490625, 0.603125, 0.559375, 0.4875  , 0.5875  , 0.553125,\n",
              "        0.475   , 0.59375 , 0.571875, 0.43125 , 0.59375 , 0.54375 ]),\n",
              " 'split4_test_score': array([0.62695925, 0.59561129, 0.61755486, 0.62695925, 0.61128527,\n",
              "        0.62068966, 0.62382445, 0.58934169, 0.62068966, 0.62695925,\n",
              "        0.59247649, 0.61755486, 0.62382445, 0.59874608, 0.62695925,\n",
              "        0.63009404, 0.60188088, 0.62382445, 0.62068966, 0.59247649,\n",
              "        0.62382445, 0.62382445, 0.60501567, 0.61442006, 0.62382445,\n",
              "        0.60188088, 0.61755486, 0.62695925, 0.61755486, 0.62068966,\n",
              "        0.62695925, 0.60815047, 0.62382445, 0.62695925, 0.61128527,\n",
              "        0.62068966, 0.62695925, 0.59874608, 0.61128527, 0.62695925,\n",
              "        0.61755486, 0.61755486, 0.62068966, 0.62068966, 0.61442006,\n",
              "        0.54231975, 0.42946708, 0.61755486, 0.55485893, 0.42633229,\n",
              "        0.63009404, 0.55485893, 0.42633229, 0.61755486, 0.52978056,\n",
              "        0.42633229, 0.62382445, 0.56112853, 0.42633229, 0.62695925,\n",
              "        0.42633229, 0.42633229, 0.63009404, 0.55172414, 0.42633229,\n",
              "        0.62382445, 0.55799373, 0.42633229, 0.62695925, 0.48589342,\n",
              "        0.42633229, 0.63636364, 0.52978056, 0.42633229, 0.63949843,\n",
              "        0.51410658, 0.42633229, 0.63636364, 0.47021944, 0.42633229,\n",
              "        0.61755486, 0.56112853, 0.42633229, 0.62382445, 0.50470219,\n",
              "        0.42633229, 0.63009404, 0.5015674 , 0.42633229, 0.63322884,\n",
              "        0.56112853, 0.57053292, 0.62382445, 0.53918495, 0.59874608,\n",
              "        0.59874608, 0.54858934, 0.60188088, 0.60815047, 0.48275862,\n",
              "        0.5799373 , 0.61755486, 0.49529781, 0.61128527, 0.62068966,\n",
              "        0.55172414, 0.60188088, 0.61128527, 0.54231975, 0.5862069 ,\n",
              "        0.62382445, 0.51410658, 0.60501567, 0.61755486, 0.4984326 ,\n",
              "        0.60188088, 0.61442006, 0.49529781, 0.60188088, 0.58934169,\n",
              "        0.46394984, 0.61442006, 0.5862069 , 0.47648903, 0.61128527,\n",
              "        0.5862069 , 0.5015674 , 0.61128527, 0.5862069 , 0.53918495,\n",
              "        0.61128527, 0.57680251, 0.53605016, 0.62382445, 0.58934169,\n",
              "        0.60188088, 0.53605016, 0.60815047, 0.61128527, 0.5015674 ,\n",
              "        0.61442006, 0.59247649, 0.5862069 , 0.62695925, 0.47648903,\n",
              "        0.55172414, 0.61755486, 0.50470219, 0.59874608, 0.5830721 ,\n",
              "        0.5015674 , 0.58934169, 0.59561129, 0.52978056, 0.5830721 ,\n",
              "        0.59247649, 0.54231975, 0.59247649, 0.62068966, 0.50783699,\n",
              "        0.59561129, 0.60188088, 0.53918495, 0.5830721 , 0.60501567,\n",
              "        0.48902821, 0.62695925, 0.61128527, 0.51410658, 0.61442006,\n",
              "        0.60501567, 0.47962382, 0.58934169, 0.56426332, 0.43887147,\n",
              "        0.63009404, 0.56426332, 0.50783699, 0.63009404, 0.5830721 ]),\n",
              " 'std_fit_time': array([7.21003457e-03, 8.26615691e-03, 4.91726090e-03, 5.78820628e-03,\n",
              "        2.18596796e-01, 1.96311742e-01, 2.91590800e-02, 7.07990787e-02,\n",
              "        1.31698109e-01, 3.46231401e-02, 1.46763608e-02, 9.07749612e-02,\n",
              "        2.11430283e-02, 1.60527850e-01, 1.38474491e-01, 2.95096949e-02,\n",
              "        9.02113280e-02, 5.76725853e-02, 4.45950628e-02, 8.07491529e-03,\n",
              "        7.19324286e-02, 6.69357407e-02, 1.13216520e-01, 1.17444201e-01,\n",
              "        2.98012206e-02, 8.20088936e-02, 5.39503582e-02, 6.31647381e-02,\n",
              "        1.67042187e-02, 1.28088669e-01, 5.01700194e-02, 3.13190050e-01,\n",
              "        9.97659009e-02, 5.55512770e-02, 3.77401054e-01, 1.68774713e-01,\n",
              "        1.05123381e-01, 3.67323943e-02, 1.47695525e-01, 1.09559447e-01,\n",
              "        6.34638995e-01, 1.82060878e-01, 9.46855930e-02, 2.74859393e-01,\n",
              "        2.24456661e-01, 1.91168006e-02, 3.32932057e-02, 6.01303693e-03,\n",
              "        2.30459995e-02, 1.62538256e-02, 1.70060279e-01, 1.97849115e-02,\n",
              "        3.14485320e-02, 2.33983250e-01, 3.00708650e-02, 8.47652986e-02,\n",
              "        1.86796446e-02, 5.10508017e-02, 3.75720373e-02, 2.17956987e-01,\n",
              "        6.49628454e-02, 4.06397478e-02, 3.52338439e-01, 5.85093725e-02,\n",
              "        5.49191634e-02, 2.43187450e-01, 6.87766580e-02, 1.14152178e-01,\n",
              "        3.56240210e-01, 5.90291204e-02, 7.93425818e-02, 5.16115351e-01,\n",
              "        2.49716800e-02, 5.07482740e-02, 1.90571793e-02, 9.04313197e-02,\n",
              "        6.68559652e-02, 8.68621514e-01, 1.50314931e-01, 4.37476137e-02,\n",
              "        1.34672174e+00, 2.04175627e+00, 1.42042016e-01, 1.45029649e+00,\n",
              "        1.22639938e-01, 1.16043353e-01, 1.58123218e+00, 7.41371892e-01,\n",
              "        7.78865634e-02, 1.96692291e+00, 2.06080829e-02, 7.99736679e-03,\n",
              "        1.77712923e-02, 1.93135823e-02, 2.96590925e-01, 3.36690281e-01,\n",
              "        5.34379789e-02, 2.04696469e-01, 1.68361691e-01, 3.68468719e-02,\n",
              "        1.81980208e-02, 2.16164524e-01, 9.51464801e-02, 3.20559303e-01,\n",
              "        2.35664434e-01, 1.84004260e-01, 2.15075843e-01, 3.28408746e-01,\n",
              "        1.30468486e+00, 1.78030549e-02, 1.15983080e-01, 1.08553504e-01,\n",
              "        4.26770753e-01, 1.57897623e-01, 1.34850560e+00, 2.29666361e-01,\n",
              "        1.84271066e-01, 2.82408088e-02, 3.53013659e-02, 1.53143334e-02,\n",
              "        3.79753021e-02, 3.63538955e-01, 1.30272815e+00, 1.43266323e-01,\n",
              "        4.53339213e-01, 8.43168820e-01, 6.82326478e-02, 2.75273177e-02,\n",
              "        4.27000794e+00, 1.02722802e+00, 1.00301469e+00, 1.08251141e-01,\n",
              "        7.94691090e-01, 9.32808591e-01, 1.71136105e+01, 2.49330433e-02,\n",
              "        3.39537350e-02, 9.54182368e-03, 6.81053820e-02, 7.63468208e-01,\n",
              "        4.21150230e-01, 5.97514180e-01, 2.18808173e-01, 3.51136414e-01,\n",
              "        3.70086700e-02, 3.43313382e-02, 1.89508066e-02, 8.67141813e-02,\n",
              "        2.57539566e-01, 4.46145289e-01, 1.69644556e+00, 2.07387588e-01,\n",
              "        5.96493775e-01, 5.47254500e-02, 4.24914086e-02, 2.08264079e-02,\n",
              "        1.00294143e-01, 1.84500672e-01, 7.27839940e-02, 2.44689040e-01,\n",
              "        4.02771970e-01, 7.55246633e-01, 3.41347529e-02, 2.96487445e-02,\n",
              "        1.52433169e-01, 3.12512611e-02, 4.83449248e-01, 4.68401693e-01,\n",
              "        1.05130906e-01, 6.66505372e-01, 4.69905073e-01, 8.84158071e-02,\n",
              "        4.79996222e-02, 3.82891406e-02, 1.37571812e-01, 2.41260847e+00,\n",
              "        1.24304195e+00, 3.62149866e-01, 1.15304218e+00, 1.33129192e+00]),\n",
              " 'std_score_time': array([1.05860641e-04, 6.18622662e-05, 3.18445121e-05, 3.65698351e-05,\n",
              "        1.20058847e-05, 3.76136574e-05, 1.13823337e-05, 3.63384330e-05,\n",
              "        1.49930221e-05, 6.57916749e-05, 3.94345771e-05, 3.35142241e-05,\n",
              "        7.63680277e-05, 3.55234402e-05, 3.44640138e-05, 6.32728232e-05,\n",
              "        3.60040790e-05, 4.09941317e-05, 1.56203978e-04, 3.78487571e-04,\n",
              "        2.89037273e-05, 4.48202579e-05, 1.01853578e-05, 2.44210464e-05,\n",
              "        1.52621936e-04, 2.99537246e-05, 1.03836697e-05, 3.06504308e-05,\n",
              "        5.11260612e-05, 2.99868024e-05, 2.84967556e-05, 3.23320208e-05,\n",
              "        2.41038236e-05, 2.48260494e-05, 3.56887687e-05, 4.75752073e-05,\n",
              "        3.59654723e-05, 5.79682992e-05, 3.57657749e-05, 2.55134171e-05,\n",
              "        4.17872075e-05, 7.46582950e-05, 8.62303805e-05, 4.14490721e-04,\n",
              "        4.32301209e-05, 6.60999161e-05, 1.49968129e-05, 4.36239550e-05,\n",
              "        5.42956111e-05, 2.75904589e-05, 4.07130703e-05, 1.99256516e-04,\n",
              "        2.48289800e-05, 2.46384118e-05, 2.75442705e-05, 1.56595820e-05,\n",
              "        3.74662944e-05, 2.47834249e-05, 7.11584844e-05, 3.27288882e-05,\n",
              "        3.02311502e-04, 1.64343571e-05, 5.62280991e-05, 9.37490958e-05,\n",
              "        5.47958308e-05, 1.53780316e-04, 2.06288672e-04, 5.89584417e-05,\n",
              "        9.07845105e-05, 5.92240581e-05, 1.08239892e-04, 8.22944958e-05,\n",
              "        4.74023625e-05, 1.27996808e-05, 2.94858918e-05, 8.10933615e-05,\n",
              "        2.46107109e-05, 4.43802977e-05, 1.73058296e-04, 1.27428876e-05,\n",
              "        7.81085465e-05, 1.37704414e-03, 2.78267883e-05, 1.78635037e-04,\n",
              "        6.16472074e-05, 2.78374705e-03, 2.30539794e-05, 3.16458253e-05,\n",
              "        6.49024245e-06, 1.74168974e-05, 1.59215092e-04, 6.37992080e-05,\n",
              "        7.25517412e-05, 1.94305145e-05, 3.45407224e-05, 8.71112452e-06,\n",
              "        7.35853561e-04, 6.54975370e-05, 5.13734007e-05, 6.19288301e-05,\n",
              "        3.19183268e-05, 2.46175495e-04, 1.58478894e-04, 2.69954803e-04,\n",
              "        4.92460833e-05, 1.96081945e-04, 1.87387903e-05, 2.75220560e-05,\n",
              "        5.46946613e-04, 2.88096211e-04, 9.01621271e-05, 1.99117320e-04,\n",
              "        2.28904683e-05, 8.95721309e-05, 4.94460788e-04, 2.50170969e-05,\n",
              "        4.01752214e-05, 5.27314635e-05, 3.85296227e-05, 1.55219101e-04,\n",
              "        2.66489395e-04, 2.54324575e-05, 4.24713372e-05, 1.22298776e-04,\n",
              "        2.11678106e-05, 9.52791759e-06, 6.64110405e-05, 7.71043473e-05,\n",
              "        2.16784636e-04, 4.47076478e-05, 1.29502283e-04, 1.66437099e-04,\n",
              "        2.82448645e-05, 1.99884461e-04, 3.42096171e-04, 6.84670084e-05,\n",
              "        6.63142152e-05, 6.32030700e-05, 2.48079241e-04, 2.29384823e-04,\n",
              "        2.48303536e-05, 1.74340664e-04, 2.69547572e-05, 1.77557665e-05,\n",
              "        1.99491628e-04, 4.49161873e-05, 2.69312122e-05, 1.50389889e-04,\n",
              "        2.47094604e-05, 1.84429530e-04, 2.12965554e-04, 4.49747186e-05,\n",
              "        2.08287798e-05, 6.77030519e-05, 6.19640668e-05, 5.81531409e-05,\n",
              "        1.50900240e-04, 3.66627312e-05, 2.40564483e-04, 2.40072238e-05,\n",
              "        7.08997688e-05, 4.64955597e-05, 1.02717852e-04, 1.14227633e-04,\n",
              "        1.67744549e-04, 4.11127659e-05, 1.78384239e-04, 2.81460782e-05,\n",
              "        1.78095966e-04, 1.25856107e-05, 2.32149678e-05, 1.31959030e-05,\n",
              "        5.83366173e-05, 2.28695993e-05, 5.85416224e-05, 8.10398365e-04,\n",
              "        7.75208175e-05, 7.29318653e-05, 3.91690308e-05, 3.51081052e-05]),\n",
              " 'std_test_score': array([0.04942689, 0.03122312, 0.03954003, 0.04957188, 0.02553217,\n",
              "        0.04091898, 0.04914956, 0.0344751 , 0.03419067, 0.04957188,\n",
              "        0.02631267, 0.04299501, 0.05065544, 0.02434581, 0.04577065,\n",
              "        0.05102804, 0.02675987, 0.03924547, 0.04906242, 0.03511052,\n",
              "        0.0445865 , 0.04936666, 0.02787735, 0.04046621, 0.04896342,\n",
              "        0.02287202, 0.04551022, 0.04942689, 0.03453365, 0.04523506,\n",
              "        0.04942689, 0.03680591, 0.04368931, 0.04931317, 0.03851269,\n",
              "        0.04558449, 0.04942689, 0.03026042, 0.04515097, 0.04942689,\n",
              "        0.03049071, 0.03912701, 0.048215  , 0.0339094 , 0.04382357,\n",
              "        0.01912956, 0.0026644 , 0.03663361, 0.0255809 , 0.00305384,\n",
              "        0.03641331, 0.05124186, 0.00235261, 0.03347445, 0.0259317 ,\n",
              "        0.00434959, 0.0418268 , 0.0494396 , 0.00538259, 0.03778036,\n",
              "        0.03824479, 0.00123021, 0.04139643, 0.0447625 , 0.00123021,\n",
              "        0.03998501, 0.05135749, 0.00123021, 0.04112813, 0.03396417,\n",
              "        0.00123021, 0.03991994, 0.01044162, 0.00123021, 0.03831149,\n",
              "        0.02960848, 0.00123021, 0.0341526 , 0.02095441, 0.00123021,\n",
              "        0.03281759, 0.02461522, 0.00123021, 0.03788314, 0.02611763,\n",
              "        0.00123021, 0.0412855 , 0.02912234, 0.00123021, 0.04333129,\n",
              "        0.03849865, 0.02692895, 0.0369963 , 0.0398626 , 0.0254381 ,\n",
              "        0.04053629, 0.01456595, 0.02733184, 0.04382509, 0.01992951,\n",
              "        0.03301481, 0.0454678 , 0.02935461, 0.02919687, 0.0413333 ,\n",
              "        0.05254223, 0.02371378, 0.03954416, 0.03754369, 0.03539377,\n",
              "        0.03559181, 0.03344141, 0.02465865, 0.0401141 , 0.04298866,\n",
              "        0.02846622, 0.0377112 , 0.04241259, 0.03197904, 0.04586851,\n",
              "        0.01398053, 0.03844804, 0.03742087, 0.00927947, 0.03563084,\n",
              "        0.03985626, 0.02380883, 0.03474459, 0.03270119, 0.04395784,\n",
              "        0.033463  , 0.0290371 , 0.03814654, 0.03164087, 0.04525151,\n",
              "        0.03716959, 0.03697395, 0.04459687, 0.03384092, 0.04112101,\n",
              "        0.04119561, 0.0404141 , 0.03496301, 0.05187697, 0.02586464,\n",
              "        0.02804834, 0.04493174, 0.02951979, 0.02215137, 0.04229742,\n",
              "        0.02138737, 0.02390339, 0.03402155, 0.02163768, 0.03001526,\n",
              "        0.04008956, 0.03737629, 0.02448775, 0.02748939, 0.02321274,\n",
              "        0.02710249, 0.04589195, 0.03872432, 0.02422369, 0.03569262,\n",
              "        0.02030892, 0.03943219, 0.04677793, 0.02232646, 0.04145662,\n",
              "        0.03687683, 0.00574077, 0.02540245, 0.02128663, 0.01837536,\n",
              "        0.03526484, 0.02073659, 0.03682682, 0.03540733, 0.03171329])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ7zEtWd9MZw",
        "colab_type": "text"
      },
      "source": [
        "## **9. Análise dos Resultados**\n",
        "\n",
        "Na curva ROC as linhas se afastam do topo e da esquerda do gráfico, indicando um alto número de falsos positivos. \n",
        "\n",
        "A capacidade de predição do modelo com Redes Neurais Artificiais foi baixa, com média de 59,3% de acerto.\n",
        "\n",
        "Ao comparar as técnicas, a capacidade de predição dos modelos é baixa em todas as utilizadas. Sendo que a técnica de Random Forest apresentou uma capacidade preditiva melhor, com 59,3% de acerto, enquanto a Árvore de Decisão apresentou 46,9% e a Rede Neural 58,9%.\n",
        "\n",
        "É provável que os dados apresentados não sejam suficientemente bons para prever a qualidade do vinho.\n",
        "\n"
      ]
    }
  ]
}